{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiyiyu/MachinePerception/blob/main/ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vLO-jWzbrE7"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "\n",
        "# General\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Metrics and Clustering (Scikit-learn)\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Plotting and Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Image and Spatial Processing (SciPy)\n",
        "from scipy import ndimage\n",
        "from scipy.spatial import distance\n",
        "from collections import Counter\n",
        "\n",
        "# Deep Learning (PyTorch and torchvision)\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "# Image Handling\n",
        "from PIL import Image\n",
        "\n",
        "# Deep Learning Utilities (d2l)\n",
        "!pip install d2l==1.0.3\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8CrfgRhT6r2"
      },
      "outputs": [],
      "source": [
        "# Code to connect Google Drive with Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-ihicp21zEs"
      },
      "source": [
        "# **TASK 1: Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting data into folders code adapted from https://aravinda-gn.medium.com/how-to-split-image-dataset-into-train-validation-and-test-set-5a41c48af332"
      ],
      "metadata": {
        "id": "pbAosT7F2gts"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qPumHlWUEQ9"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Machine Perception/assignment'\n",
        "\n",
        "for filename in glob.glob(os.path.join(path, 'digits.png')):\n",
        "    # Similar to pracs, simply for testing\n",
        "    print(\"\\n *********** IMAGE \" + filename.split('/')[-1] + \" ************ \\n\")\n",
        "    img = cv.imread(filename)\n",
        "    print(\"The image file name is: \", os.path.basename(filename))\n",
        "    height, width, channels = img.shape\n",
        "    print(\"The image height is: \", height)\n",
        "    print(\"The image width is: \", width)\n",
        "    tiny_images = []\n",
        "    labels = []\n",
        "\n",
        "    # Extract tiny images of 20x20 from digits.png\n",
        "    for i in range(0, img.shape[0], 20):\n",
        "        for j in range(0, img.shape[1], 20):\n",
        "            tiny_image = img[i:i+20, j:j+20]\n",
        "            tiny_images.append(tiny_image)\n",
        "            labels.append(i // (20 * 5))  # assuming each 5 rows corresponds to a different digit\n",
        "\n",
        "    # Shuffle and split the images and labels together\n",
        "    # 50 rows x 100 columns = 5000 tiny images with 5 rows for each digit\n",
        "    combined = list(zip(tiny_images, labels))\n",
        "    random.shuffle(combined)\n",
        "    tiny_images[:], labels[:] = zip(*combined)\n",
        "    split_idx = int(0.8 * len(tiny_images))\n",
        "    train_images = tiny_images[:split_idx]\n",
        "    train_labels = labels[:split_idx]\n",
        "    test_images = tiny_images[split_idx:]\n",
        "    test_labels = labels[split_idx:]\n",
        "\n",
        "    base_path = '/content/drive/MyDrive/Machine Perception/assignment'\n",
        "    train_folder_path = os.path.join(base_path, 'Train')\n",
        "    test_folder_path = os.path.join(base_path, 'Test')\n",
        "\n",
        "    # Check if split already done previously\n",
        "    if not os.listdir(train_folder_path) and not os.listdir(test_folder_path):\n",
        "        os.makedirs(train_folder_path, exist_ok=True)\n",
        "        os.makedirs(test_folder_path, exist_ok=True)\n",
        "\n",
        "        # Split into test and train folder with labeling\n",
        "        for idx, (image, label) in enumerate(zip(train_images, train_labels)):\n",
        "            cv.imwrite(f'{train_folder_path}/train_{label}_{idx}.png', image)\n",
        "\n",
        "        for idx, (image, label) in enumerate(zip(test_images, test_labels)):\n",
        "            cv.imwrite(f'{test_folder_path}/test_{label}_{idx}.png', image)\n",
        "    else:\n",
        "        print(\"Train and Test folders already contain images. Skipping saving process.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bri4sweFsHw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c91b936-2e2d-4521-9d4a-52003a6b8e32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape:  (1000, 2000, 3)\n"
          ]
        }
      ],
      "source": [
        "filename = os.path.join(path, 'digits.png')\n",
        "\n",
        "img = cv.imread(filename)\n",
        "print(\"Image shape: \", img.shape)\n",
        "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "# Split the image into 5000 cells, each 20x20 size\n",
        "cells = [np.hsplit(row, 100) for row in np.vsplit(gray, 50)]\n",
        "# Transform into a numpy array with size (50,100,20,20)\n",
        "x = np.array(cells)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qRYDmzR3NiX"
      },
      "source": [
        "# **TASK 2: K-Nearest Neighbour**\n",
        "This code was adapted from the template in Practical 5 Exercise 3 https://drive.google.com/file/d/18qFWCetJolvJWRXm_YI4KUyEaEtc_4S-/view?usp=sharing and OpenCV KNN tutorial https://docs.opencv.org/4.x/d5/d26/tutorial_py_knn_understanding.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AlB4UFQscaQ"
      },
      "source": [
        "**Multi-class Classification**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING ACCURACY\n",
        "\n",
        "# Prepare training data and test data\n",
        "train = x[:, :5].reshape(-1, 400).astype(np.float32)  # Size should be (250,400)\n",
        "test = x[:, 5:100].reshape(-1, 400).astype(np.float32)  # Size should be (4750,400)\n",
        "\n",
        "# Create labels for train and test data\n",
        "c = np.arange(10)  # 10 classes, 0-9\n",
        "train_labels = np.repeat(c, 25)[:, np.newaxis]  # Should create 250 labels\n",
        "test_labels = np.repeat(c, 475)[:, np.newaxis]  # Should create 4750 labels\n",
        "\n",
        "# Initialize KNN\n",
        "knn = cv.ml.KNearest_create()\n",
        "\n",
        "# Train KNN model on training data\n",
        "knn.train(train, cv.ml.ROW_SAMPLE, train_labels)\n",
        "\n",
        "# Specify the number of neighbors in k-NN\n",
        "k_neighbours = 3 # Odd values for majority voting\n",
        "\n",
        "# Test KNN model on test data\n",
        "ret, result, neighbours, dist = knn.findNearest(train, k=k_neighbours)\n",
        "\n",
        "print(\"\\nResults for k = \", k_neighbours)\n",
        "\n",
        "# Evaluate model's accuracy\n",
        "matches = result == train_labels\n",
        "correct = np.count_nonzero(matches)\n",
        "accuracy = correct * 100.0 / result.size\n",
        "print(f\"\\nAverage Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Individual accuracies\n",
        "accuracies = []\n",
        "for digit in range(10):\n",
        "    digit_indices = np.where(train_labels == digit)\n",
        "    true_labels_digit = train_labels[digit_indices]\n",
        "    predicted_labels_digit = result[digit_indices]\n",
        "\n",
        "    accuracy = accuracy_score(true_labels_digit, predicted_labels_digit) * 100\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Accuracy for digit {digit}: {accuracy:.2f}%\")\n",
        "\n",
        "# Compute the confusion matrix\n",
        "matrix = confusion_matrix(train_labels.ravel(), result.ravel())\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(matrix)"
      ],
      "metadata": {
        "id": "fjy_TRijptLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nG2zpe0ss5n"
      },
      "outputs": [],
      "source": [
        "# TESTING ACCURACY\n",
        "\n",
        "# Prepare training data and test data\n",
        "train = x[:, :5].reshape(-1, 400).astype(np.float32)  # Size should be (250,400)\n",
        "test = x[:, 5:100].reshape(-1, 400).astype(np.float32)  # Size should be (4750,400)\n",
        "\n",
        "# Create labels for train and test data\n",
        "c = np.arange(10)  # 10 classes, 0-9\n",
        "train_labels = np.repeat(c, 25)[:, np.newaxis]  # Should create 250 labels\n",
        "test_labels = np.repeat(c, 475)[:, np.newaxis]  # Should create 4750 labels\n",
        "\n",
        "# Initialize KNN\n",
        "knn = cv.ml.KNearest_create()\n",
        "\n",
        "# Train KNN model on training data\n",
        "knn.train(train, cv.ml.ROW_SAMPLE, train_labels)\n",
        "\n",
        "# Specify the number of neighbors in k-NN\n",
        "k_neighbours = 1 # Odd values for majority voting\n",
        "\n",
        "# Test KNN model on test data\n",
        "ret, result, neighbours, dist = knn.findNearest(test, k=k_neighbours)\n",
        "\n",
        "print(\"\\nResults for k = \", k_neighbours)\n",
        "\n",
        "# Evaluate model's accuracy\n",
        "matches = result == test_labels\n",
        "correct = np.count_nonzero(matches)\n",
        "accuracy = correct * 100.0 / result.size\n",
        "print(f\"\\nAverage Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Individual accuracies\n",
        "accuracies = []\n",
        "for digit in range(10):\n",
        "    digit_indices = np.where(test_labels == digit)\n",
        "    true_labels_digit = test_labels[digit_indices]\n",
        "    predicted_labels_digit = result[digit_indices]\n",
        "\n",
        "    accuracy = accuracy_score(true_labels_digit, predicted_labels_digit) * 100\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Accuracy for digit {digit}: {accuracy:.2f}%\")\n",
        "\n",
        "# Compute the confusion matrix\n",
        "matrix = confusion_matrix(test_labels.ravel(), result.ravel())\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T86DkhmisNsp"
      },
      "source": [
        "**Binary Classification** (similar to practicals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbKuU_B6p5V8"
      },
      "outputs": [],
      "source": [
        "# Prepare training data and test data\n",
        "train = x[0:10,:5].reshape(-1,400).astype(np.float32) # Size = (500,400) ; first 5 rows: 0, second 5 row: 1  Use 5% (first 5 columns for trainning)\n",
        "test = x[0:10,5:100].reshape(-1,400).astype(np.float32) # Size = (500,400)\n",
        "\n",
        "# Create labels for train and test data\n",
        "c = np.arange(2)  ## 2 classes\n",
        "train_labels = np.repeat(c,25)[:,np.newaxis]\n",
        "test_labels = np.repeat(c,475)[:,np.newaxis]\n",
        "\n",
        "# Initialize KNN\n",
        "knn = cv.ml.KNearest_create()\n",
        "\n",
        "# Train KNN model on training data\n",
        "knn.train(train, cv.ml.ROW_SAMPLE, train_labels)\n",
        "\n",
        "# Specify the number of neighbors in k-NN\n",
        "k_neighbours = 1 # Odd values for majority voting\n",
        "\n",
        "# Test KNN model on test data\n",
        "ret, result, neighbours, dist = knn.findNearest(test, k=k_neighbours)\n",
        "\n",
        "print(\"\\nResults for k = \", k_neighbours)\n",
        "\n",
        "# Evaluate model's accuracy\n",
        "matches = result == test_labels\n",
        "correct = np.count_nonzero(matches)\n",
        "accuracy = correct * 100.0 / result.size\n",
        "print(f\"\\nAverage Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# Individual accuracies\n",
        "accuracies = []\n",
        "for digit in range(2):\n",
        "    digit_indices = np.where(test_labels == digit)\n",
        "    true_labels_digit = test_labels[digit_indices]\n",
        "    predicted_labels_digit = result[digit_indices]\n",
        "\n",
        "    accuracy = accuracy_score(true_labels_digit, predicted_labels_digit) * 100\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    print(f\"Accuracy for digit {digit}: {accuracy:.2f}%\")\n",
        "\n",
        "# Compute the confusion matrix\n",
        "matrix = confusion_matrix(test_labels.ravel(), result.ravel())\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTXZpALK3Uz7"
      },
      "source": [
        "# **TASK 3: Linear SVM**\n",
        "This code was adapted from the template in Practical 5 Exercise 3 https://drive.google.com/file/d/18qFWCetJolvJWRXm_YI4KUyEaEtc_4S-/view?usp=sharing and OpenCV SVM tutorial https://docs.opencv.org/4.x/d1/d73/tutorial_introduction_to_svm.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br3Iz31luUvu"
      },
      "outputs": [],
      "source": [
        "# Assuming data has been prepared as Task 2\n",
        "\n",
        "# One-vs-Rest SVM with varying C values\n",
        "\n",
        "# Prepare training data and test data\n",
        "# train = x[:, :5].reshape(-1, 400).astype(np.float32)  # Size should be (250,400)\n",
        "# test = x[:, 5:100].reshape(-1, 400).astype(np.float32)  # Size should be (4750,400)\n",
        "\n",
        "# # Create labels for train and test data\n",
        "# c = np.arange(10)  # 10 classes, 0-9\n",
        "# train_labels = np.repeat(c, 25)[:, np.newaxis]  # Should create 250 labels\n",
        "# test_labels = np.repeat(c, 475)[:, np.newaxis]  # Should create 4750 labels\n",
        "\n",
        "# Define C values for SVM hyperparameter tuning\n",
        "C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000] # logarithmic\n",
        "\n",
        "# Initialize list to store accuracy for each C value\n",
        "accuracies = []\n",
        "\n",
        "# Loop through each C value\n",
        "for C in C_values:\n",
        "    svms = []\n",
        "    # Train an SVM for each digit\n",
        "    for i in range(10):\n",
        "        svm = cv.ml.SVM_create()\n",
        "        svm.setType(cv.ml.SVM_C_SVC)\n",
        "        svm.setKernel(cv.ml.SVM_LINEAR)\n",
        "        svm.setC(C)\n",
        "        svm.setTermCriteria((cv.TERM_CRITERIA_MAX_ITER, 100, 1e-8))\n",
        "\n",
        "        labels = np.where(train_labels == i, 1, -1)\n",
        "        svm.train(train, cv.ml.ROW_SAMPLE, labels)\n",
        "        svms.append(svm)\n",
        "\n",
        "    # Initiliaze list to store predictions\n",
        "    predictions = []\n",
        "    for sample in test:\n",
        "        distances = []\n",
        "        for svm in svms:\n",
        "            _, r = svm.predict(sample.reshape(1, 400))\n",
        "            distances.append(r[0][0])\n",
        "        # Classify digit based on highest decision function value\n",
        "        predictions.append(np.argmax(distances))\n",
        "\n",
        "    # Calculate accuracy\n",
        "    correct = np.count_nonzero(np.array(predictions) == test_labels.ravel())\n",
        "    accuracy = correct * 100.0 / len(predictions)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f\"\\nFor C = {C}, Average Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # Compute the confusion matrix\n",
        "    matrix = confusion_matrix(test_labels.ravel(), result.ravel())\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(matrix)\n",
        "\n",
        "# # Plot accuracies against different C values\n",
        "# plt.figure(figsize=(10,6))\n",
        "# plt.semilogx(C_values, accuracies, marker='o', linestyle='-')\n",
        "# plt.title('Average Accuracy vs. C values')\n",
        "# plt.xlabel('C value (log scale)')\n",
        "# plt.ylabel('Accuracy (%)')\n",
        "# plt.grid(True, which=\"both\", ls=\"--\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DECirT9s3U_x"
      },
      "source": [
        "# **TASK 4: Bag of Visual Words**\n",
        "This code was adapted from the following template https://medium.com/@aybukeyalcinerr/bag-of-visual-words-bovw-db9500331b2f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc9uNkSsU5Q6"
      },
      "outputs": [],
      "source": [
        "# Step 1: Load train and test images into dictionaries.\n",
        "def load_images_from_folder(folder):\n",
        "    images = {}\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv.imread(img_path, 0)    # grayscale\n",
        "\n",
        "        # Apply histogram equalization\n",
        "        img = cv.equalizeHist(img)\n",
        "\n",
        "        if img is not None:\n",
        "            # Extract label from filename, assuming filename format is: [label]_[index].png\n",
        "            label = filename.split('_')[1]\n",
        "\n",
        "            if label not in images:\n",
        "                images[label] = []\n",
        "            images[label].append(img)\n",
        "    return images\n",
        "\n",
        "train_images = load_images_from_folder(train_folder_path)\n",
        "test_images = load_images_from_folder(test_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGsn1_wTXnfj"
      },
      "outputs": [],
      "source": [
        "# Step 2: Extract local features from images using SIFT.\n",
        "def sift_features(images, nfeatures=150):\n",
        "    sift_vectors = {}\n",
        "    descriptor_list = []\n",
        "    sift = cv.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
        "\n",
        "    for label, img_list in images.items():\n",
        "        features = []\n",
        "        for img in img_list:\n",
        "            kp, des = sift.detectAndCompute(img, None)\n",
        "            if des is not None:  # Check if descriptors are found\n",
        "                descriptor_list.extend(des)\n",
        "                features.append(des)\n",
        "        sift_vectors[label] = features\n",
        "    return [descriptor_list, sift_vectors]\n",
        "\n",
        "sifts = sift_features(train_images, nfeatures=150)\n",
        "# Takes the descriptor list which is unordered one\n",
        "descriptor_list = sifts[0]\n",
        "# Takes the sift features that is seperated class by class for train data\n",
        "all_bovw_feature = sifts[1]\n",
        "# Takes the sift features that is seperated class by class for test data\n",
        "test_bovw_feature = sift_features(test_images, nfeatures=100)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoU9GHuxYXck"
      },
      "outputs": [],
      "source": [
        "# Step 3: Send the visual dictionary to the k-means clustering algorithm and find the visual words which are center points.\n",
        "def kmeans(k, descriptor_list):\n",
        "    kmeans = KMeans(n_clusters = k, n_init=10)\n",
        "    kmeans.fit(descriptor_list)\n",
        "    visual_words = kmeans.cluster_centers_\n",
        "    return visual_words\n",
        "\n",
        "# Takes the central points which is visual words\n",
        "visual_words = kmeans(600, descriptor_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlJeNddTXKrO"
      },
      "outputs": [],
      "source": [
        "# Step 4: Create histograms for both test and train images\n",
        "def find_index(image, center):\n",
        "    count = 0\n",
        "    ind = 0\n",
        "\n",
        "    for i in range(len(center)):\n",
        "        if(i == 0):\n",
        "           count = distance.euclidean(image, center[i])\n",
        "        else:\n",
        "            dist = distance.euclidean(image, center[i])\n",
        "            if(dist < count):\n",
        "                ind = i\n",
        "                count = dist\n",
        "    return ind\n",
        "\n",
        "def image_class(all_bovw, centers):\n",
        "    dict_feature = {}\n",
        "    for key, value in all_bovw.items():\n",
        "        category = []\n",
        "        for img in value:\n",
        "            histogram = np.zeros(len(centers))\n",
        "            if img is not None:  # Check if descriptors are found\n",
        "                for each_feature in img:\n",
        "                    ind = find_index(each_feature, centers)\n",
        "                    histogram[ind] += 1\n",
        "            # Normalize the histogram\n",
        "            histogram = histogram / histogram.sum()\n",
        "            category.append(histogram)\n",
        "        dict_feature[key] = category\n",
        "    return dict_feature\n",
        "\n",
        "bovw_train = image_class(all_bovw_feature, visual_words)\n",
        "bovw_test = image_class(test_bovw_feature, visual_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUq3C_f1_mll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9c7ccd-f7bd-4a25-8a62-eb809084a8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy: %71.41316073354909\n",
            "\n",
            "Class based accuracies: \n",
            "\n",
            "0 : %96.5909090909091\n",
            "1 : %97.05882352941177\n",
            "2 : %61.111111111111114\n",
            "3 : %73.25581395348837\n",
            "4 : %78.26086956521739\n",
            "5 : %59.78260869565217\n",
            "6 : %54.54545454545454\n",
            "7 : %61.111111111111114\n",
            "8 : %83.72093023255815\n",
            "9 : %63.0\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Predict classes of the test images with k-NN function.\n",
        "def knn(images, tests, k=1):\n",
        "  num_test = 0\n",
        "  correct_predict = 0\n",
        "  class_based = {}\n",
        "\n",
        "  for test_key, test_val in tests.items():\n",
        "      class_based[test_key] = [0, 0] # [correct, all]\n",
        "      for tst in test_val:\n",
        "          distances = []\n",
        "          for train_key, train_val in images.items():\n",
        "              for train in train_val:\n",
        "                  dist = distance.euclidean(tst, train)\n",
        "                  distances.append((train_key, dist))\n",
        "\n",
        "          # Sort by distance and get the labels of the k-nearest training samples\n",
        "          votes = [i[0] for i in sorted(distances, key=lambda x: x[1])[:k]]\n",
        "\n",
        "          # Get the most common class among the neighbors\n",
        "          vote_result = Counter(votes).most_common(1)[0][0]\n",
        "\n",
        "          if(test_key == vote_result):\n",
        "              correct_predict += 1\n",
        "              class_based[test_key][0] += 1\n",
        "          num_test += 1\n",
        "          class_based[test_key][1] += 1\n",
        "\n",
        "  return [num_test, correct_predict, class_based]\n",
        "\n",
        "# Call the knn function\n",
        "results_bowl = knn(bovw_train, bovw_test, k=9)\n",
        "\n",
        "# Step 6: Calculate the accuracy\n",
        "def accuracy(results):\n",
        "    avg_accuracy = (results[1] / results[0]) * 100\n",
        "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
        "    print(\"\\nClass based accuracies: \\n\")\n",
        "\n",
        "    # Ensure keys are strings representing integers, then sort\n",
        "    sorted_keys = sorted(results[2].keys(), key=lambda x: int(x))\n",
        "\n",
        "    for key in sorted_keys:\n",
        "        value = results[2][key]\n",
        "        acc = (value[0] / value[1]) * 100\n",
        "        print(key + \" : %\" + str(acc))\n",
        "\n",
        "# Calculates the accuracies and write the results to the console.\n",
        "accuracy(results_bowl)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "# Step 5: Predict classes of the test images with SVM.\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for label, histograms in bovw_train.items():\n",
        "    for histogram in histograms:\n",
        "        X_train.append(histogram)\n",
        "        y_train.append(label)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.05, random_state=10)\n",
        "\n",
        "# Train an SVM classifier\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Validate the classifier\n",
        "y_pred = clf.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "id": "1lJBaDnusI0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIG4awiN3VIc"
      },
      "source": [
        "# **TASK 5: Convolutional Neural Networks**\n",
        "This code was adapted from the template from Practical 7 https://colab.research.google.com/github/d2l-ai/d2l-pytorch-colab/blob/master/chapter_computer-vision/fine-tuning.ipynb and Pytorch documentation on pre-trained models https://pytorch.org/vision/stable/models.html\n",
        "\n",
        "Custom Dataset (DigitsDataset) code adapted from Pytorch data loading tutorial https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ResNet MODELS**"
      ],
      "metadata": {
        "id": "NmWwWygxG_Lc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4KNTnCaPu2K"
      },
      "outputs": [],
      "source": [
        "# Create custom dataset for existing data to work with Dataloader and ResNet architecture\n",
        "class DigitsDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "        self.filenames = os.listdir(path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.path, self.filenames[idx])\n",
        "        image = cv.imread(img_name)\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        label = int(self.filenames[idx].split('_')[1])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data transformations and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = DigitsDataset(train_folder_path, transform=transform)\n",
        "test_dataset = DigitsDataset(test_folder_path, transform=transform)\n",
        "\n",
        "# Number of epochs declared here to use later for time\n",
        "number_epochs = 5\n",
        "\n",
        "# Fine tuning method\n",
        "def resnet_fine_tuning(net, learning_rate, batch_size=256, num_epochs=number_epochs, param_group=True):\n",
        "    # Data loaders\n",
        "    train_iter = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_iter = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Device configuration\n",
        "    devices = [torch.device('cuda' if torch.cuda.is_available() else 'cpu')]\n",
        "    net = net.to(devices[0])\n",
        "\n",
        "    # Loss function\n",
        "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "    # Optimizer setup\n",
        "    if param_group:\n",
        "        params_1x = [param for name, param in net.named_parameters() if name not in [\"fc.weight\", \"fc.bias\"]]\n",
        "        trainer = torch.optim.SGD([{'params': params_1x},\n",
        "                                   {'params': net.fc.parameters(), 'lr': learning_rate * 10}],\n",
        "                                  lr=learning_rate, weight_decay=0.001)\n",
        "    else:\n",
        "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)\n",
        "\n",
        "    # Training\n",
        "    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and modify the pre-trained ResNet-18\n",
        "finetune_resnet18 = models.resnet18(pretrained=True)\n",
        "finetune_resnet18.fc = nn.Linear(finetune_resnet18.fc.in_features, 10)  # 10 classes\n",
        "nn.init.xavier_uniform_(finetune_resnet18.fc.weight)\n",
        "\n",
        "# Initialize start time for calculating time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "resnet_fine_tuning(finetune_resnet18, 5e-5)\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# Calculate average training time of one epoch\n",
        "avg_time_epoch = total_time / number_epochs\n",
        "\n",
        "# Print time results\n",
        "print(f\"Total time: {total_time:.2f} seconds\")\n",
        "print(f\"Average time per epoch: {avg_time_epoch:.2f} seconds\")"
      ],
      "metadata": {
        "id": "ulxmYCglGllo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and modify pre-trained ResNet-34\n",
        "finetune_resnet34 = torchvision.models.resnet34(pretrained=True)\n",
        "finetune_resnet34.fc = nn.Linear(finetune_resnet34.fc.in_features, 10) # 10 classes\n",
        "nn.init.xavier_uniform_(finetune_resnet34.fc.weight);\n",
        "\n",
        "# Initialize start time for calculating time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "resnet_fine_tuning(finetune_resnet34, 5e-5)\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# Calculate average training time of one epoch\n",
        "avg_time_epoch = total_time / number_epochs\n",
        "\n",
        "# Print time results\n",
        "print(f\"Total time: {total_time:.2f} seconds\")\n",
        "print(f\"Average time per epoch: {avg_time_epoch:.2f} seconds\")"
      ],
      "metadata": {
        "id": "fph_r1bTgkPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and modify pre-trained ResNet-50\n",
        "finetune_resnet50 = torchvision.models.resnet50(pretrained=True)\n",
        "finetune_resnet50.fc = nn.Linear(finetune_resnet50.fc.in_features, 10) # 10 classes\n",
        "nn.init.xavier_uniform_(finetune_resnet50.fc.weight);\n",
        "\n",
        "# Initialize start time for calculating time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "resnet_fine_tuning(finetune_resnet50, 5e-5)\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# Calculate average training time of one epoch\n",
        "avg_time_epoch = total_time / number_epochs\n",
        "\n",
        "# Print time results\n",
        "print(f\"Total time: {total_time:.2f} seconds\")\n",
        "print(f\"Average time per epoch: {avg_time_epoch:.2f} seconds\")"
      ],
      "metadata": {
        "id": "onCO1qH6fz_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Alex and VGG Net**"
      ],
      "metadata": {
        "id": "N3QbDlTAHpqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create custom dataset for existing data to work with Dataloader and Alex/VGG Net architecture.\n",
        "class DigitsDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.path = path\n",
        "        self.transform = transform\n",
        "        self.filenames = os.listdir(path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.path, self.filenames[idx])\n",
        "        image = cv.imread(img_name)\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)  # Convert to PIL Image\n",
        "        label = int(self.filenames[idx].split('_')[1])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Data transformations and normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to fit Alex/VGG Net input size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = DigitsDataset(train_folder_path, transform=transform)\n",
        "test_dataset = DigitsDataset(test_folder_path, transform=transform)\n",
        "\n",
        "# Number of epochs declared here to use later for time\n",
        "number_epochs = 5\n",
        "\n",
        "# Fine tuning method\n",
        "def alexvgg_fine_tuning(net, learning_rate, batch_size=32, num_epochs=number_epochs, param_group=True):\n",
        "    # Data loaders\n",
        "    train_iter = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_iter = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Device configuration\n",
        "    devices = [torch.device('cuda' if torch.cuda.is_available() else 'cpu')]\n",
        "    net = net.to(devices[0])\n",
        "\n",
        "    # Loss function\n",
        "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "    # Optimizer setup\n",
        "    if param_group:\n",
        "        params_1x = [param for name, param in net.named_parameters() if \"classifier.6\" not in name]\n",
        "        trainer = torch.optim.SGD([{'params': params_1x},\n",
        "                                   {'params': net.classifier[6].parameters(), 'lr': learning_rate * 10}],\n",
        "                                  lr=learning_rate, weight_decay=0.001)\n",
        "    else:\n",
        "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)\n",
        "\n",
        "    # Training\n",
        "    d2l.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
      ],
      "metadata": {
        "id": "Lc1_Y9-wUKIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and modify the pre-trained AlexNet\n",
        "finetune_alexnet = models.alexnet(pretrained=True)\n",
        "finetune_alexnet.classifier[6] = nn.Linear(finetune_alexnet.classifier[6].in_features, 10)  # 10 classes\n",
        "nn.init.xavier_uniform_(finetune_alexnet.classifier[6].weight)\n",
        "\n",
        "# Initialize start time for calculating time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "alexvgg_fine_tuning(finetune_alexnet, 5e-5)\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# Calculate average training time of one epoch\n",
        "avg_time_epoch = total_time / number_epochs\n",
        "\n",
        "# Print time results\n",
        "print(f\"Total time: {total_time:.2f} seconds\")\n",
        "print(f\"Average time per epoch: {avg_time_epoch:.2f} seconds\")"
      ],
      "metadata": {
        "id": "0Lm4F6vlJHRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and modify pre-trained VGG Net\n",
        "finetune_vggnet = models.vgg16(pretrained=True)\n",
        "finetune_vggnet.classifier[6] = nn.Linear(finetune_vggnet.classifier[6].in_features, 10)  # 10 classes\n",
        "nn.init.xavier_uniform_(finetune_vggnet.classifier[6].weight)\n",
        "\n",
        "# Initialize start time for calculating time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "alexvgg_fine_tuning(finetune_vggnet, 5e-5)\n",
        "\n",
        "# Calculate total training time\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "# Calculate average training time of one epoch\n",
        "avg_time_epoch = total_time / number_epochs\n",
        "\n",
        "# Print time results\n",
        "print(f\"Total time: {total_time:.2f} seconds\")\n",
        "print(f\"Average time per epoch: {avg_time_epoch:.2f} seconds\")"
      ],
      "metadata": {
        "id": "NdCC4p9eapPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}